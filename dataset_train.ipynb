{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset_train.ipynb","provenance":[],"collapsed_sections":["cX1rRZ7w2ji7","9md-qIBJ6LKN"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lJG4_UTQY3Md","colab_type":"code","outputId":"12eb4e74-53d1-423d-b749-63934e2acbf7","executionInfo":{"status":"ok","timestamp":1590002180054,"user_tz":-330,"elapsed":5460,"user":{"displayName":"KUNAL MOHTA","photoUrl":"","userId":"01077738230215571285"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","# drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CnoLbIclWPMh","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import os\n","import sys\n","# import random\n","# import math\n","# import re\n","# import time\n","import numpy as np\n","import cv2\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import urllib.request\n","import shutil\n","import zipfile\n","import skimage.color\n","import skimage.io\n","import skimage.transform\n","import imgaug\n","\n","root_dir = os.path.abspath(\"/content/drive/My Drive/maskrcnn-nnfl/Mask_RCNN\") # KUNAL'S path\n","#ROOT_DIR = os.path.abspath(\"/content/drive/.shortcut-targets-by-id/18VderTbR8Ygk4oZ9m8Upm57jX9-b5oo6/repos/Mask_RCNN\") # KUNAL'S path\n","\n","# mask rcnn import\n","sys.path.append(root_dir)\n","from mrcnn.config import Config\n","from mrcnn import utils\n","import mrcnn.model as modellib\n","from mrcnn import visualize\n","from mrcnn.model import log\n","\n","model_dir = os.path.join(root_dir, \"logs\")\n","\n","sys.path.append(os.path.join(root_dir, \"samples/coco/\"))  # To find local version\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","\n","from pycocotools import mask as maskUtils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhiOWSmMOUx-","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/maskrcnn-nnfl/Mask_RCNN/samples/coco/smaller_dataset /content/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cX1rRZ7w2ji7","colab_type":"text"},"source":["# Dataset download"]},{"cell_type":"code","metadata":{"id":"cu5eHJfJt5bA","colab_type":"code","colab":{}},"source":["dataType = \"val\"\n","dataYear = \"2014\"\n","dataDir = \"./dataset\"\n","\n","# # Setup paths and file names\n","# if dataType == \"minival\" or dataType == \"valminusminival\":\n","#     imgDir = \"{}/{}{}\".format(dataDir, \"val\", dataYear)\n","#     imgZipFile = \"{}/{}{}.zip\".format(dataDir, \"val\", dataYear)\n","#     imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(\"val\", dataYear)\n","# else:\n","#     imgDir = \"{}/{}{}\".format(dataDir, dataType, dataYear)\n","#     imgZipFile = \"{}/{}{}.zip\".format(dataDir, dataType, dataYear)\n","#     imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(dataType, dataYear)\n","# # print(\"Image paths:\"); print(imgDir); print(imgZipFile); print(imgURL)\n","\n","# # Create main folder if it doesn't exist yet\n","# if not os.path.exists(dataDir):\n","#     os.makedirs(dataDir)\n","\n","# # Download images if not available locally\n","# if not os.path.exists(imgDir):\n","#     os.makedirs(imgDir)\n","#     # print(\"Downloading images to \" + imgZipFile + \" ...\")\n","#     # with urllib.request.urlopen(imgURL) as resp, open(imgZipFile, 'wb') as out:\n","#     #     shutil.copyfileobj(resp, out)\n","#     # print(\"... done downloading.\")\n","#     print(\"Unzipping \" + imgZipFile)\n","#     with zipfile.ZipFile(imgZipFile, \"r\") as zip_ref:\n","#         zip_ref.extractall(dataDir)\n","#     print(\"... done unzipping\")\n","# print(\"Will use images in \" + imgDir)\n","\n","# # Setup annotations data paths\n","# annDir = \"{}/annotations\".format(dataDir)\n","# if dataType == \"minival\":\n","#     annZipFile = \"{}/instances_minival2014.json.zip\".format(dataDir)\n","#     annFile = \"{}/instances_minival2014.json\".format(annDir)\n","#     annURL = \"https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0\"\n","#     unZipDir = annDir\n","# elif dataType == \"valminusminival\":\n","#     annZipFile = \"{}/instances_valminusminival2014.json.zip\".format(dataDir)\n","#     annFile = \"{}/instances_valminusminival2014.json\".format(annDir)\n","#     annURL = \"https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0\"\n","#     unZipDir = annDir\n","# else:\n","#     annZipFile = \"{}/annotations_trainval{}.zip\".format(dataDir, dataYear)\n","#     annFile = \"{}/instances_{}{}.json\".format(annDir, dataType, dataYear)\n","#     annURL = \"http://images.cocodataset.org/annotations/annotations_trainval{}.zip\".format(dataYear)\n","#     unZipDir = dataDir\n","# print(\"Annotations paths:\"); print(annDir); print(annFile); print(annZipFile); print(annURL)\n","\n","# # Download annotations if not available locally\n","# print(annDir)\n","# if not os.path.exists(annDir):\n","#     os.makedirs(annDir)\n","# if not os.path.exists(annFile):\n","#     if not os.path.exists(annZipFile):\n","#         print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n","#         with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n","#             shutil.copyfileobj(resp, out)\n","#         print(\"... done downloading.\")\n","#     print(\"Unzipping \" + annZipFile)\n","#     print(annZipFile)\n","#     with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n","#         zip_ref.extractall(unZipDir)\n","#     print(\"... done unzipping\")\n","# print(\"Will use annotations in \" + annFile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpqbZIyoCHz7","colab_type":"code","colab":{}},"source":["# print(len(os.listdir('./dataset/train2014')))\n","# print(len(os.listdir('./val2014')))\n","# print(os.listdir('./dataset/train2014'))\n","# import json\n","# with open('./dataset/annotations/instances_val2014.json') as f:\n","#   data = json.load(f)\n","# print(data.keys())\n","# print(len(data['images']))\n","# print(data['annotations'][0])\n","# !unzip -l ./dataset/val2014.zip | wc\n","# !zip -T ./dataset/val2014.zip\n","# print(\"here\")\n","# !zip -T ./dataset/train2014.zip\n","# !unzip ./dataset/val2014.zip -d ./dataset/\n","# !jar xvf ./dataset/val2014.zip\n","# !jar --help\n","# !ls ./dataset/train2014 | wc\n","\n","# mkdir /content/dataset\n","# !cd dataset\n","# !jar xvf /content/drive/My\\ Drive/repos/Mask_RCNN/samples/coco/dataset/val2014.zip\n","# print(len(os.listdir('/content/val2014')))\n","\n","# !cp /content/drive/My\\ Drive/repos/Mask_RCNN/samples/coco/dataset/train2014.zip /content/\n","# !cp /content/drive/My\\ Drive/repos/Mask_RCNN/samples/coco/dataset/val2014.zip /content/\n","# !jar xvf /content/train2014.zip\n","# !jar xvf /content/val2014.zip\n","\n","# !cp -r /content/drive/My\\ Drive/repos/Mask_RCNN/samples/coco/dataset/annotations /content/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lu_XI8zVJgv","colab_type":"code","colab":{}},"source":["# mv val2014 ./dataset/\n","# ls ./dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhcQeC7NwrXe","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/repos/Mask_RCNN/samples/coco/smaller_dataset /content/\n","# !rm -rf /content/smaller_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9md-qIBJ6LKN","colab_type":"text"},"source":["# Loading datasets"]},{"cell_type":"code","metadata":{"id":"0_IV_ghcJONl","colab_type":"code","colab":{}},"source":["# dataset_dir = './dataset'\n","# # subset = 'train'\n","# year = '2014'\n","\n","# train_coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, 'train', year))\n","# val_coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, 'val', year))\n","# minival_coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, 'minival', year))\n","# valminusminival_coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, 'valminusminival', year))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhW-KQQz30vb","colab_type":"code","outputId":"7e84a5d3-5428-4a18-c881-8591eebbf38d","executionInfo":{"status":"error","timestamp":1589958936746,"user_tz":-330,"elapsed":1180,"user":{"displayName":"HIMANK METHI","photoUrl":"","userId":"11448742258872026096"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["# print(\"Train:\", len(list(train_coco.imgs.keys())), \"imgs\")\n","# print(\"Val:\", len(list(val_coco.imgs.keys())), \"imgs\")\n","# print(\"Minival:\", len(list(minival_coco.imgs.keys())), \"imgs\")\n","# print(\"Valminusminival:\", len(list(valminusminival_coco.imgs.keys())), \"imgs\")"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-500822e3ffe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_coco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Val:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_coco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Minival:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminival_coco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Valminusminival:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalminusminival_coco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_coco' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"QObHVnXbO7yN","colab_type":"text"},"source":["# class CocoDataset()"]},{"cell_type":"code","metadata":{"id":"HOG9Lcnw4Ogt","colab_type":"code","colab":{}},"source":["class CocoDataset():\n","    def __init__(self):\n","        # self._image_ids = []\n","        self.image_ids = []\n","        self.image_info = []\n","        self.class_info = [{\"source\": \"\", \"id\": 0, \"name\": \"BG\"}]\n","        self.source_class_ids = {}\n","\n","    # @property\n","    # def image_ids(self):\n","    #     return self._image_ids\n","\n","    def prepare(self):\n","        # Build (or rebuild) everything else from the info dicts.\n","        self.num_classes = len(self.class_info)\n","        self.class_names = [\",\".join(ci[\"name\"].split(\",\")[:1]) for ci in self.class_info]\n","        self.num_images = len(self.image_info)\n","        # self._image_ids = np.arange(self.num_images)\n","        self.image_ids = np.arange(self.num_images)\n","        self.class_ids = np.arange(self.num_classes)\n","\n","        # source to id dict\n","        self.source_to_class_id = {\"{}.{}\".format(info['source'], info['id']): id\n","                                      for info, id in zip(self.class_info, self.class_ids)}\n","        # self.image_from_source_map = {\"{}.{}\".format(info['source'], info['id']): id\n","        #                               for info, id in zip(self.image_info, self.image_ids)}\n","\n","        self.sources = list(set([info['source'] for info in self.class_info]))\n","        self.source_class_ids = {}\n","        for source in self.sources:\n","            self.source_class_ids[source] = []\n","            for i, info in enumerate(self.class_info):\n","                if i == 0 or source == info['source']:\n","                    self.source_class_ids[source].append(i)\n","\n","    def load_coco(self, dataset_dir, subset, class_ids=None, return_coco=False):\n","        coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, subset, 2014))\n","        if subset == \"minival\" or subset == \"valminusminival\":\n","            subset = \"val\"\n","        # image_dir = \"{}/{}{}\".format(dataset_dir, subset, '2014')\n","\n","        if class_ids is None: # all images\n","            class_ids = sorted(coco.getCatIds())\n","\n","        if class_ids: # subset\n","            image_ids = []\n","            for id in class_ids:\n","                image_ids.extend(list(coco.getImgIds(catIds=[id])))\n","            image_ids = list(set(image_ids)) # remove dups\n","        else: # all images\n","            image_ids = list(coco.imgs.keys())\n","\n","        # adding classes\n","        for i in class_ids:\n","            # self.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])\n","            for info in self.class_info:\n","                if info['source'] == \"coco\" and info[\"id\"] == i:\n","                    return\n","            # class not already present\n","            self.class_info.append({\n","                \"source\": \"coco\",\n","                \"id\": i,\n","                \"name\": coco.loadCats(i)[0][\"name\"],\n","            })\n","\n","        # image info\n","        for i in image_ids:\n","            image_info = {\n","                \"id\": i,\n","                \"source\": \"coco\",\n","                \"path\": os.path.join(\"{}/{}{}\".format(dataset_dir, subset, '2014'), coco.imgs[i]['file_name']),\n","                \"width\": coco.imgs[i][\"width\"],\n","                \"height\": coco.imgs[i][\"height\"],\n","                \"annotations\": coco.loadAnns(coco.getAnnIds(\n","                    imgIds=[i], catIds=class_ids, iscrowd=None))\n","            }\n","            self.image_info.append(image_info)\n","            # self.add_image(\n","            #     \"coco\", image_id=i,\n","            #     path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n","            #     width=coco.imgs[i][\"width\"],\n","            #     height=coco.imgs[i][\"height\"],\n","            #     annotations=coco.loadAnns(coco.getAnnIds(\n","                    # imgIds=[i], catIds=class_ids, iscrowd=None)))\n","\n","        if return_coco:\n","            return coco\n","\n","    # def map_source_class_id(self, source_class_id):\n","    #     return self.source_to_class[source_class_id]\n","\n","    def load_image(self, image_id):\n","        image = skimage.io.imread(self.image_info[image_id]['path'])\n","        # convert to rgb if not\n","        if image.ndim != 3:\n","            image = skimage.color.gray2rgb(image)\n","        # remove alpha if there\n","        if image.shape[-1] == 4:\n","            image = image[..., :3]\n","        return image\n","\n","    def load_mask(self, img_id):\n","        img = self.image_info[img_id]\n","        # if image_info[\"source\"] != \"coco\":\n","        #     return super(CocoDataset, self).load_mask(image_id)\n","\n","        curr_masks = []\n","        cls_ids = []\n","        anns = self.image_info[img_id][\"annotations\"]\n","        for ann in anns:\n","            # class_id = self.map_source_class_id(\n","            #     \"coco.{}\".format(annotation['category_id']))\n","            cls_id = self.source_to_class_id[\"coco.{}\".format(ann['category_id'])]\n","            if cls_id:\n","                msk = self.annToMask(ann, img[\"height\"],\n","                                   img[\"width\"])\n","                if msk.max() < 1:\n","                    continue\n","                if ann['iscrowd']:\n","                    # -ve class id for crowd\n","                    cls_id *= -1\n","                    if msk.shape[0] != img[\"height\"] or msk.shape[1] != img[\"width\"]:\n","                        msk = np.ones([img[\"height\"], img[\"width\"]], dtype=bool)\n","                curr_masks.append(msk)\n","                cls_ids.append(cls_id)\n","\n","        # curr masks into array\n","        if cls_ids:\n","            msk = np.stack(curr_masks, axis=2).astype(np.bool)\n","            cls_ids = np.array(cls_ids, dtype=np.int32)\n","            return msk, cls_ids\n","        else:\n","            # empty mask\n","            msk = np.empty([0, 0, 0])\n","            cls_ids = np.empty([0], np.int32)\n","            return msk, cls_ids\n","            # return super(CocoDataset, self).load_mask(image_id)\n","\n","    def annToMask(self, ann, h, w):\n","        seg = ann['segmentation']\n","        if isinstance(seg, list):\n","            rles = maskUtils.frPyObjects(seg, h, w)\n","            out_rle = maskUtils.merge(rles)\n","        elif isinstance(seg['counts'], list):\n","            # uncompressed rle\n","            out_rle = maskUtils.frPyObjects(seg, h, w)\n","        else:\n","            out_rle = ann['segmentation']\n","        msk = maskUtils.decode(out_rle)\n","        return msk"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4JUTA_Ax9Pei","colab_type":"code","outputId":"b629a30d-a4aa-496c-e456-6631b619bbd3","executionInfo":{"status":"ok","timestamp":1590002301522,"user_tz":-330,"elapsed":956,"user":{"displayName":"KUNAL MOHTA","photoUrl":"","userId":"01077738230215571285"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["dataset = '/content/smaller_dataset'\n","dataset_train = CocoDataset()\n","dataset_train.load_coco(dataset, \"train\")\n","\n","# dataset_train.load_coco(dataset, \"valminusminival\", year='2014')\n","dataset_train.prepare()\n","\n","# Validation dataset\n","dataset_val = CocoDataset()\n","val_type = \"minival\"\n","dataset_val.load_coco(dataset, val_type)\n","dataset_val.prepare()\n","\n","# Image Augmentation\n","# Right/Left flip 50% of the time\n","augmentation = imgaug.augmenters.Fliplr(0.5)\n","\n","# *** This training schedule is an example. Update to your needs ***"],"execution_count":13,"outputs":[{"output_type":"stream","text":["loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dxBIOsxJL8gj","colab_type":"code","outputId":"6562e058-f377-44a5-a04d-325d074df812","executionInfo":{"status":"ok","timestamp":1590002306320,"user_tz":-330,"elapsed":1007,"user":{"displayName":"KUNAL MOHTA","photoUrl":"","userId":"01077738230215571285"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["# need to remove config\n","class CocoConfig(Config):\n","  IMAGES_PER_GPU = 1\n","  \n","  #NUM_CLASSES=1+80\n","\n","config = CocoConfig()\n","config.display()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     1\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.7\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 1\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                13\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           None\n","NUM_CLASSES                    1\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                1000\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yVRrR6uY8yN8","colab_type":"code","outputId":"3a9ceea3-1704-42ed-8027-a805840b572b","executionInfo":{"status":"ok","timestamp":1590002326421,"user_tz":-330,"elapsed":18558,"user":{"displayName":"KUNAL MOHTA","photoUrl":"","userId":"01077738230215571285"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["model = modellib.MaskRCNN(mode=\"training\", config=CocoConfig(), model_dir=model_dir)\n","#model.load_weights(last_weights, by_name=True)"],"execution_count":15,"outputs":[{"output_type":"stream","text":[" \n","123456789\n"," \n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","scores= Tensor(\"ROI/strided_slice:0\", shape=(?, ?), dtype=float32)\n","ix= Tensor(\"ROI/top_anchors:1\", shape=(?, 6000), dtype=int32)\n","scores= Tensor(\"ROI/ExpandDims:0\", shape=(1, 6000), dtype=float32)\n","deltas= Tensor(\"ROI/ExpandDims_1:0\", shape=(1, 6000, 4), dtype=float32)\n","pre_nms_anchors= Tensor(\"ROI/ExpandDims_2:0\", shape=(1, 6000, 4), dtype=float32)\n","boxes= Tensor(\"ROI/ExpandDims_3:0\", shape=(1, 6000, 4), dtype=float32)\n","boxes= Tensor(\"ROI/ExpandDims_4:0\", shape=(1, 6000, 4), dtype=float32)\n","proposals= Tensor(\"ROI/ExpandDims_5:0\", shape=(1, ?, 4), dtype=float32)\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/maskrcnn-nnfl-github/Mask_RCNN/mrcnn/model.py:1361: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/maskrcnn-nnfl-github/Mask_RCNN/mrcnn/model.py:354: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/maskrcnn-nnfl-github/Mask_RCNN/mrcnn/model.py:1407: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aB91KpqeQUHo","colab_type":"text"},"source":["# Training - Stage 1\n"]},{"cell_type":"code","metadata":{"id":"kaB-gOzjIKC0","colab_type":"code","outputId":"98d4b1e7-476a-42cb-f9c8-65516299fa1c","executionInfo":{"status":"ok","timestamp":1590000804732,"user_tz":-330,"elapsed":190846,"user":{"displayName":"KUNAL MOHTA","photoUrl":"","userId":"01077738230215571285"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","print(\"Training network heads\")\n","model.train(dataset_train, dataset_val,\n","            learning_rate=0.001,\n","            epochs=10,\n","            layers='all',\n","            augmentation=augmentation,\n","            steps_per_epoch=10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training network heads\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /content/drive/My Drive/repos/Mask_RCNN/logs/coco20200520T1844/mask_rcnn_coco_{epoch:04d}.h5\n","Selecting layers to train\n","conv1                  (Conv2D)\n","bn_conv1               (BatchNormalization)\n","res2a_branch2a         (Conv2D)\n","bn2a_branch2a          (BatchNormalization)\n","res2a_branch2b         (Conv2D)\n","bn2a_branch2b          (BatchNormalization)\n","res2a_branch2c         (Conv2D)\n","res2a_branch1          (Conv2D)\n","bn2a_branch2c          (BatchNormalization)\n","bn2a_branch1           (BatchNormalization)\n","res2b_branch2a         (Conv2D)\n","bn2b_branch2a          (BatchNormalization)\n","res2b_branch2b         (Conv2D)\n","bn2b_branch2b          (BatchNormalization)\n","res2b_branch2c         (Conv2D)\n","bn2b_branch2c          (BatchNormalization)\n","res2c_branch2a         (Conv2D)\n","bn2c_branch2a          (BatchNormalization)\n","res2c_branch2b         (Conv2D)\n","bn2c_branch2b          (BatchNormalization)\n","res2c_branch2c         (Conv2D)\n","bn2c_branch2c          (BatchNormalization)\n","res3a_branch2a         (Conv2D)\n","bn3a_branch2a          (BatchNormalization)\n","res3a_branch2b         (Conv2D)\n","bn3a_branch2b          (BatchNormalization)\n","res3a_branch2c         (Conv2D)\n","res3a_branch1          (Conv2D)\n","bn3a_branch2c          (BatchNormalization)\n","bn3a_branch1           (BatchNormalization)\n","res3b_branch2a         (Conv2D)\n","bn3b_branch2a          (BatchNormalization)\n","res3b_branch2b         (Conv2D)\n","bn3b_branch2b          (BatchNormalization)\n","res3b_branch2c         (Conv2D)\n","bn3b_branch2c          (BatchNormalization)\n","res3c_branch2a         (Conv2D)\n","bn3c_branch2a          (BatchNormalization)\n","res3c_branch2b         (Conv2D)\n","bn3c_branch2b          (BatchNormalization)\n","res3c_branch2c         (Conv2D)\n","bn3c_branch2c          (BatchNormalization)\n","res3d_branch2a         (Conv2D)\n","bn3d_branch2a          (BatchNormalization)\n","res3d_branch2b         (Conv2D)\n","bn3d_branch2b          (BatchNormalization)\n","res3d_branch2c         (Conv2D)\n","bn3d_branch2c          (BatchNormalization)\n","res4a_branch2a         (Conv2D)\n","bn4a_branch2a          (BatchNormalization)\n","res4a_branch2b         (Conv2D)\n","bn4a_branch2b          (BatchNormalization)\n","res4a_branch2c         (Conv2D)\n","res4a_branch1          (Conv2D)\n","bn4a_branch2c          (BatchNormalization)\n","bn4a_branch1           (BatchNormalization)\n","res4b_branch2a         (Conv2D)\n","bn4b_branch2a          (BatchNormalization)\n","res4b_branch2b         (Conv2D)\n","bn4b_branch2b          (BatchNormalization)\n","res4b_branch2c         (Conv2D)\n","bn4b_branch2c          (BatchNormalization)\n","res4c_branch2a         (Conv2D)\n","bn4c_branch2a          (BatchNormalization)\n","res4c_branch2b         (Conv2D)\n","bn4c_branch2b          (BatchNormalization)\n","res4c_branch2c         (Conv2D)\n","bn4c_branch2c          (BatchNormalization)\n","res4d_branch2a         (Conv2D)\n","bn4d_branch2a          (BatchNormalization)\n","res4d_branch2b         (Conv2D)\n","bn4d_branch2b          (BatchNormalization)\n","res4d_branch2c         (Conv2D)\n","bn4d_branch2c          (BatchNormalization)\n","res4e_branch2a         (Conv2D)\n","bn4e_branch2a          (BatchNormalization)\n","res4e_branch2b         (Conv2D)\n","bn4e_branch2b          (BatchNormalization)\n","res4e_branch2c         (Conv2D)\n","bn4e_branch2c          (BatchNormalization)\n","res4f_branch2a         (Conv2D)\n","bn4f_branch2a          (BatchNormalization)\n","res4f_branch2b         (Conv2D)\n","bn4f_branch2b          (BatchNormalization)\n","res4f_branch2c         (Conv2D)\n","bn4f_branch2c          (BatchNormalization)\n","res4g_branch2a         (Conv2D)\n","bn4g_branch2a          (BatchNormalization)\n","res4g_branch2b         (Conv2D)\n","bn4g_branch2b          (BatchNormalization)\n","res4g_branch2c         (Conv2D)\n","bn4g_branch2c          (BatchNormalization)\n","res4h_branch2a         (Conv2D)\n","bn4h_branch2a          (BatchNormalization)\n","res4h_branch2b         (Conv2D)\n","bn4h_branch2b          (BatchNormalization)\n","res4h_branch2c         (Conv2D)\n","bn4h_branch2c          (BatchNormalization)\n","res4i_branch2a         (Conv2D)\n","bn4i_branch2a          (BatchNormalization)\n","res4i_branch2b         (Conv2D)\n","bn4i_branch2b          (BatchNormalization)\n","res4i_branch2c         (Conv2D)\n","bn4i_branch2c          (BatchNormalization)\n","res4j_branch2a         (Conv2D)\n","bn4j_branch2a          (BatchNormalization)\n","res4j_branch2b         (Conv2D)\n","bn4j_branch2b          (BatchNormalization)\n","res4j_branch2c         (Conv2D)\n","bn4j_branch2c          (BatchNormalization)\n","res4k_branch2a         (Conv2D)\n","bn4k_branch2a          (BatchNormalization)\n","res4k_branch2b         (Conv2D)\n","bn4k_branch2b          (BatchNormalization)\n","res4k_branch2c         (Conv2D)\n","bn4k_branch2c          (BatchNormalization)\n","res4l_branch2a         (Conv2D)\n","bn4l_branch2a          (BatchNormalization)\n","res4l_branch2b         (Conv2D)\n","bn4l_branch2b          (BatchNormalization)\n","res4l_branch2c         (Conv2D)\n","bn4l_branch2c          (BatchNormalization)\n","res4m_branch2a         (Conv2D)\n","bn4m_branch2a          (BatchNormalization)\n","res4m_branch2b         (Conv2D)\n","bn4m_branch2b          (BatchNormalization)\n","res4m_branch2c         (Conv2D)\n","bn4m_branch2c          (BatchNormalization)\n","res4n_branch2a         (Conv2D)\n","bn4n_branch2a          (BatchNormalization)\n","res4n_branch2b         (Conv2D)\n","bn4n_branch2b          (BatchNormalization)\n","res4n_branch2c         (Conv2D)\n","bn4n_branch2c          (BatchNormalization)\n","res4o_branch2a         (Conv2D)\n","bn4o_branch2a          (BatchNormalization)\n","res4o_branch2b         (Conv2D)\n","bn4o_branch2b          (BatchNormalization)\n","res4o_branch2c         (Conv2D)\n","bn4o_branch2c          (BatchNormalization)\n","res4p_branch2a         (Conv2D)\n","bn4p_branch2a          (BatchNormalization)\n","res4p_branch2b         (Conv2D)\n","bn4p_branch2b          (BatchNormalization)\n","res4p_branch2c         (Conv2D)\n","bn4p_branch2c          (BatchNormalization)\n","res4q_branch2a         (Conv2D)\n","bn4q_branch2a          (BatchNormalization)\n","res4q_branch2b         (Conv2D)\n","bn4q_branch2b          (BatchNormalization)\n","res4q_branch2c         (Conv2D)\n","bn4q_branch2c          (BatchNormalization)\n","res4r_branch2a         (Conv2D)\n","bn4r_branch2a          (BatchNormalization)\n","res4r_branch2b         (Conv2D)\n","bn4r_branch2b          (BatchNormalization)\n","res4r_branch2c         (Conv2D)\n","bn4r_branch2c          (BatchNormalization)\n","res4s_branch2a         (Conv2D)\n","bn4s_branch2a          (BatchNormalization)\n","res4s_branch2b         (Conv2D)\n","bn4s_branch2b          (BatchNormalization)\n","res4s_branch2c         (Conv2D)\n","bn4s_branch2c          (BatchNormalization)\n","res4t_branch2a         (Conv2D)\n","bn4t_branch2a          (BatchNormalization)\n","res4t_branch2b         (Conv2D)\n","bn4t_branch2b          (BatchNormalization)\n","res4t_branch2c         (Conv2D)\n","bn4t_branch2c          (BatchNormalization)\n","res4u_branch2a         (Conv2D)\n","bn4u_branch2a          (BatchNormalization)\n","res4u_branch2b         (Conv2D)\n","bn4u_branch2b          (BatchNormalization)\n","res4u_branch2c         (Conv2D)\n","bn4u_branch2c          (BatchNormalization)\n","res4v_branch2a         (Conv2D)\n","bn4v_branch2a          (BatchNormalization)\n","res4v_branch2b         (Conv2D)\n","bn4v_branch2b          (BatchNormalization)\n","res4v_branch2c         (Conv2D)\n","bn4v_branch2c          (BatchNormalization)\n","res4w_branch2a         (Conv2D)\n","bn4w_branch2a          (BatchNormalization)\n","res4w_branch2b         (Conv2D)\n","bn4w_branch2b          (BatchNormalization)\n","res4w_branch2c         (Conv2D)\n","bn4w_branch2c          (BatchNormalization)\n","res5a_branch2a         (Conv2D)\n","bn5a_branch2a          (BatchNormalization)\n","res5a_branch2b         (Conv2D)\n","bn5a_branch2b          (BatchNormalization)\n","res5a_branch2c         (Conv2D)\n","res5a_branch1          (Conv2D)\n","bn5a_branch2c          (BatchNormalization)\n","bn5a_branch1           (BatchNormalization)\n","res5b_branch2a         (Conv2D)\n","bn5b_branch2a          (BatchNormalization)\n","res5b_branch2b         (Conv2D)\n","bn5b_branch2b          (BatchNormalization)\n","res5b_branch2c         (Conv2D)\n","bn5b_branch2c          (BatchNormalization)\n","res5c_branch2a         (Conv2D)\n","bn5c_branch2a          (BatchNormalization)\n","res5c_branch2b         (Conv2D)\n","bn5c_branch2b          (BatchNormalization)\n","res5c_branch2c         (Conv2D)\n","bn5c_branch2c          (BatchNormalization)\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n"],"name":"stdout"},{"output_type":"stream","text":["/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","10/10 [==============================] - 69s 7s/step - loss: 11.6589 - val_loss: 5.5921\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/10\n","10/10 [==============================] - 16s 2s/step - loss: 14.5327 - val_loss: 5.7658\n","Epoch 3/10\n","10/10 [==============================] - 16s 2s/step - loss: 11.9209 - val_loss: 5.7750\n","Epoch 4/10\n","10/10 [==============================] - 16s 2s/step - loss: 12.5659 - val_loss: 5.7481\n","Epoch 5/10\n","10/10 [==============================] - 16s 2s/step - loss: 11.6465 - val_loss: 5.4648\n","Epoch 6/10\n","10/10 [==============================] - 16s 2s/step - loss: 11.7027 - val_loss: 5.8786\n","Epoch 7/10\n","10/10 [==============================] - 16s 2s/step - loss: 13.1471 - val_loss: 6.2325\n","Epoch 8/10\n","10/10 [==============================] - 16s 2s/step - loss: 13.0992 - val_loss: 6.5958\n","Epoch 9/10\n","10/10 [==============================] - 16s 2s/step - loss: 11.0236 - val_loss: 6.1489\n","Epoch 10/10\n","10/10 [==============================] - 16s 2s/step - loss: 11.9835 - val_loss: 6.2774\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wU-SNpS1zyO5","colab_type":"text"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"waoKI2cy7iba","colab_type":"code","outputId":"5ff81a4b-8caf-4a6d-f23a-6f25c611f07e","executionInfo":{"status":"ok","timestamp":1589959670046,"user_tz":-330,"elapsed":18,"user":{"displayName":"HIMANK METHI","photoUrl":"","userId":"11448742258872026096"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# get weigths from the latest training\n","# Get directory names. Each directory corresponds to a model\n","dir_names = next(os.walk(model_dir))[1]\n","key = \"coco\" # NAME in config class\n","dir_names = filter(lambda f: f.startswith(key), dir_names)\n","dir_names = sorted(dir_names)\n","if not dir_names:\n","    import errno\n","    raise FileNotFoundError(\n","        errno.ENOENT,\n","        \"Could not find model directory under {}\".format(model_dir))\n","# Pick last directory\n","dir_name = os.path.join(model_dir, dir_names[-1])\n","# Find the last checkpoint\n","checkpoints = next(os.walk(dir_name))[2]\n","print(checkpoints)\n","checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n","checkpoints = sorted(checkpoints)\n","if not checkpoints:\n","    import errno\n","    raise FileNotFoundError(\n","        errno.ENOENT, \"Could not find weight files in {}\".format(dir_name))\n","checkpoint = os.path.join(dir_name, checkpoints[-1])\n","print(checkpoint)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['events.out.tfevents.1589959285.3101652c4c05', 'mask_rcnn_coco_0001.h5', 'mask_rcnn_coco_0002.h5', 'mask_rcnn_coco_0003.h5', 'mask_rcnn_coco_0004.h5', 'mask_rcnn_coco_0005.h5', 'mask_rcnn_coco_0006.h5', 'mask_rcnn_coco_0007.h5', 'mask_rcnn_coco_0008.h5', 'mask_rcnn_coco_0009.h5', 'mask_rcnn_coco_0010.h5']\n","/content/drive/My Drive/repos/Mask_RCNN/logs/coco20200520T0720/mask_rcnn_coco_0010.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vFy7Hzz13Yjx","colab_type":"code","colab":{}},"source":["weights = checkpoint # last weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWAcejkr01Ty","colab_type":"code","outputId":"8a3fadf6-882c-455e-8185-3ce5dfbaf7b4","executionInfo":{"status":"error","timestamp":1589959677702,"user_tz":-330,"elapsed":7664,"user":{"displayName":"HIMANK METHI","photoUrl":"","userId":"11448742258872026096"}},"colab":{"base_uri":"https://localhost:8080/","height":659}},"source":["model = modellib.MaskRCNN(mode=\"inference\", model_dir=model_dir, config=CocoConfig())\n","model.load_weights(weights, by_name=True) # init model again after running this\n","                                          # if need to start fresh training"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" \n","qwertyuiop\n"," \n","scores= Tensor(\"ROI_1/strided_slice:0\", shape=(?, ?), dtype=float32)\n","ix= Tensor(\"ROI_1/top_anchors:1\", shape=(?, ?), dtype=int32)\n","scores= Tensor(\"ROI_1/ExpandDims:0\", shape=(1, ?), dtype=float32)\n","deltas= Tensor(\"ROI_1/ExpandDims_1:0\", shape=(1, ?, 4), dtype=float32)\n","pre_nms_anchors= Tensor(\"ROI_1/ExpandDims_2:0\", shape=(1, ?, 4), dtype=float32)\n","boxes= Tensor(\"ROI_1/ExpandDims_3:0\", shape=(1, ?, 4), dtype=float32)\n","boxes= Tensor(\"ROI_1/ExpandDims_4:0\", shape=(1, ?, 4), dtype=float32)\n","proposals= Tensor(\"ROI_1/ExpandDims_5:0\", shape=(1, ?, 4), dtype=float32)\n","WARNING:tensorflow:From /content/drive/My Drive/repos/Mask_RCNN/mrcnn/model_1.py:1476: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/repos/Mask_RCNN/mrcnn/model_1.py:1478: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/repos/Mask_RCNN/mrcnn/model_1.py:1528: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-57c355eb6395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCocoConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# init model again after running this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                                           \u001b[0;31m# if need to start fresh training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/repos/Mask_RCNN/mrcnn/model_1.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                          \u001b[0;34m' has shape {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                                          \u001b[0;34m', but the saved weight has shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m                                          str(weight_values[i].shape) + '.')\n\u001b[0m\u001b[1;32m   1329\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m                     weight_value_tuples.append((symbolic_weights[i],\n","\u001b[0;31mValueError\u001b[0m: Layer #391 (named \"mrcnn_bbox_fc\"), weight <tf.Variable 'mrcnn_bbox_fc_1/kernel:0' shape=(1024, 324) dtype=float32> has shape (1024, 324), but the saved weight has shape (1024, 4)."]}]},{"cell_type":"code","metadata":{"id":"e5ncaX0wI9l9","colab_type":"code","colab":{}},"source":["class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n","               'bus', 'train', 'truck', 'boat', 'traffic light',\n","               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n","               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n","               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n","               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n","               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n","               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n","               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n","               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n","               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n","               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n","               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n","               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n","               'teddy bear', 'hair drier', 'toothbrush']\n","               \n","img_dir = '/content/smaller_dataset/val2014/'\n","img = skimage.io.imread(img_dir+os.listdir(img_dir)[1])\n","\n","out = model.detect([img], verbose=1)\n","\n","visualize.display_instances(img, out[0]['rois'], out[0]['masks'], out[0]['class_ids'], \n","                            class_names, out[0]['scores'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_3-dORlJaSb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}